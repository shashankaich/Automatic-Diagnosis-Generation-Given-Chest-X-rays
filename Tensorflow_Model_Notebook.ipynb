{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Urm3q6WJB8sb"
   },
   "source": [
    "# Automatic Diagnosis Generation Given Chest X-rays With Bahdanau Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Compute-Word-Embeddings-using-Gensim\" data-toc-modified-id=\"Compute-Word-Embeddings-using-Gensim-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Compute Word Embeddings using Gensim</a></span></li><li><span><a href=\"#Split-data-into-train-and-test\" data-toc-modified-id=\"Split-data-into-train-and-test-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Split data into train and test</a></span></li><li><span><a href=\"#Data-Tokenization-and-Making-Batches\" data-toc-modified-id=\"Data-Tokenization-and-Making-Batches-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data Tokenization and Making Batches</a></span></li><li><span><a href=\"#Encoder-Decoder-Model\" data-toc-modified-id=\"Encoder-Decoder-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Encoder Decoder Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#X-Ray-Encoder\" data-toc-modified-id=\"X-Ray-Encoder-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>X-Ray Encoder</a></span></li><li><span><a href=\"#X-Ray-Attention\" data-toc-modified-id=\"X-Ray-Attention-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>X-Ray Attention</a></span></li><li><span><a href=\"#Decoder\" data-toc-modified-id=\"Decoder-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Decoder</a></span></li><li><span><a href=\"#Optimizer-and-Loss-Function\" data-toc-modified-id=\"Optimizer-and-Loss-Function-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Optimizer and Loss Function</a></span></li></ul></li><li><span><a href=\"#Model-Training\" data-toc-modified-id=\"Model-Training-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Model Training</a></span></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Model Evaluation</a></span></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Conclusions</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VODkw6TuxU4W",
    "outputId": "e3a3be2d-d656-43fa-d1f7-8e0ebda2af2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# mounting drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "drive_path = '/content/gdrive/My Drive/Assignments_Drive/Case_Study_2/Medical_Data'\n",
    "# specifying paths\n",
    "txt_path = drive_path + '/ecgen'\n",
    "img_path = drive_path + '/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "HO11sbfWCbhH",
    "outputId": "3e7b3ae9-c907-4cad-9fdd-7219e30bf307"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.execute_cells_below()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Javascript\n",
    "display(Javascript('IPython.notebook.execute_cells_below()'))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YWuq8qBN8aG",
    "outputId": "240aaf58-a52a-4580-f414-6cf848f65b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.2.post1\n",
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "#!pip install tensorflow-gpu==2.3\n",
    "#!pip install scikit-learn==0.20.4\n",
    "# !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "# !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.txt.gz\"\n",
    "\n",
    "# from tensorflow.python.framework import ops\n",
    "# ops.disable_eager_execution()\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "import io\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import zeros\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from PIL import Image\n",
    "from pickle import dump\n",
    "from pickle import load \n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import pickle\n",
    "\n",
    "import tensorflow \n",
    "print(tensorflow.__version__)\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.backend import categorical_crossentropy\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# setting the random seeds\n",
    "SEED = 4\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "#os.environ['TF_CUDNN_DETERMINISTIC'] = '4'  # new flag present in tf 2.0+\n",
    "np.random.seed(SEED)\n",
    "tensorflow.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvWMoI2AUjvq"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "pDfkWlh7UR_I",
    "outputId": "f96a160c-aa8b-4ca4-f6fe-1b7d668cc34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2610, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>FINDINGS</th>\n",
       "      <th>IMPRESSION</th>\n",
       "      <th>IMAGES</th>\n",
       "      <th>IMAGE_FEATURE_1</th>\n",
       "      <th>IMAGE_FEATURE_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR3691</td>\n",
       "      <td>&lt;start&gt; the heart is normal in size the medias...</td>\n",
       "      <td>&lt;start&gt; no acute disease &lt;end&gt;</td>\n",
       "      <td>[CXR3691_IM-1842-1001, CXR3691_IM-1842-3003]</td>\n",
       "      <td>(tf.Tensor(0.00026685063, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(4.9858256e-05, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR3682</td>\n",
       "      <td>&lt;start&gt; the lungs are hypoventilated there is ...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary abnormality &lt;...</td>\n",
       "      <td>[CXR3682_IM-1834-1001, CXR3682_IM-1834-2001]</td>\n",
       "      <td>(tf.Tensor(0.00033830438, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(6.356468e-05, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR3685</td>\n",
       "      <td>&lt;start&gt; calcified thoracic aorta mild rightwar...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary findings &lt;end&gt;</td>\n",
       "      <td>[CXR3685_IM-1836-1001, CXR3685_IM-1836-1002]</td>\n",
       "      <td>(tf.Tensor(0.00016475626, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(0.0002226108, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR37</td>\n",
       "      <td>&lt;start&gt; the heart is normal in size the medias...</td>\n",
       "      <td>&lt;start&gt; no acute disease &lt;end&gt;</td>\n",
       "      <td>[CXR37_IM-1847-0001-0001, CXR37_IM-1847-0001-0...</td>\n",
       "      <td>(tf.Tensor(2.0698715e-05, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(0.00041303012, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR3703</td>\n",
       "      <td>&lt;start&gt; the eamination consists of frontal and...</td>\n",
       "      <td>&lt;start&gt; no evidence of acute cardiopulmonary p...</td>\n",
       "      <td>[CXR3703_IM-1850-1001, CXR3703_IM-1850-2001]</td>\n",
       "      <td>(tf.Tensor(0.0003913842, shape=(), dtype=float...</td>\n",
       "      <td>(tf.Tensor(5.5506534e-06, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UID  ...                                    IMAGE_FEATURE_2\n",
       "0  CXR3691  ...  (tf.Tensor(4.9858256e-05, shape=(), dtype=floa...\n",
       "1  CXR3682  ...  (tf.Tensor(6.356468e-05, shape=(), dtype=float...\n",
       "2  CXR3685  ...  (tf.Tensor(0.0002226108, shape=(), dtype=float...\n",
       "3    CXR37  ...  (tf.Tensor(0.00041303012, shape=(), dtype=floa...\n",
       "4  CXR3703  ...  (tf.Tensor(5.5506534e-06, shape=(), dtype=floa...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from the pickle file\n",
    "data = pd.read_pickle(drive_path + '/data_final.pkl')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JvXCZxwheRQD",
    "outputId": "999312e5-b401-4b84-f72e-3f7170c370aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661 unique impressions\n",
      "<start> no acute cardiopulmonary abnormality <end>                                                                                         388\n",
      "<start> no acute cardiopulmonary findings <end>                                                                                            177\n",
      "<start> no acute cardiopulmonary disease <end>                                                                                             145\n",
      "<start> no acute cardiopulmonary abnormalities <end>                                                                                       127\n",
      "<start> no active disease <end>                                                                                                            105\n",
      "                                                                                                                                          ... \n",
      "<start> mild stable cardiomegaly with mild central pulmonary vascular congestion and interstitial accentuation, edema <end>                  1\n",
      "<start> vague patchy opacity in the right midlung which may represent an early pneumonia given patient is history <end>                      1\n",
      "<start> no radiographic evidence for thoracic metastases <end>                                                                               1\n",
      "<start> no evidence of active tuberculosis <end>                                                                                             1\n",
      "<start> increasing density in the superior segment the left lower lobe, seen on lateral view, consistent worsening of known tumor <end>      1\n",
      "Name: IMPRESSION, Length: 170, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# see the unique impressions\n",
    "print(str(len(data.IMPRESSION.unique())) + ' unique impressions')\n",
    "\n",
    "print(data.IMPRESSION.value_counts()[:170])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipHtgxMTQAkW"
   },
   "source": [
    "## Compute Word Embeddings using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kGnPujqQWKNy",
    "outputId": "23345d54-c668-4a4d-facf-82ebee34b36d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610\n",
      "2610\n",
      "5220\n"
     ]
    }
   ],
   "source": [
    "# get all the sentences of the Findings and Impression\n",
    "\n",
    "FIND = data.FINDINGS.values.tolist()\n",
    "IMPR = data.IMPRESSION.values.tolist()\n",
    "\n",
    "# get all the sentences in an array\n",
    "TOTAL = FIND + IMPR\n",
    "\n",
    "# check lengths of the array\n",
    "print(len(FIND))\n",
    "print(len(IMPR))\n",
    "print(len(TOTAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3Ly-P1gWgUs",
    "outputId": "7f14f07e-d1f3-429e-86f3-062eb18653b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5220\n",
      "1314\n"
     ]
    }
   ],
   "source": [
    "# create a tokenizer for the total text\n",
    "total_tokenizer = tensorflow.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "total_tokenizer.fit_on_texts(TOTAL)\n",
    "\n",
    "# get the dict for the total texts\n",
    "total_dict = total_tokenizer.word_index\n",
    "\n",
    "# get the tokens\n",
    "total_tokens = total_tokenizer.texts_to_sequences(TOTAL)\n",
    "\n",
    "# check lengths of the tokens\n",
    "print(len(total_tokens))\n",
    "print(len(total_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e0MCpfvxcuht"
   },
   "outputs": [],
   "source": [
    "# convert the sentences into array of words\n",
    "\n",
    "def convert_to_sentences(total_tokens):\n",
    "    sentences = list()\n",
    "    # get tokens for a sentence\n",
    "    for tokens in total_tokens:\n",
    "        sent = list()\n",
    "        # add each word to a sent\n",
    "        for token in tokens:\n",
    "            sent.append(total_tokenizer.index_word[token])\n",
    "        sentences.append(sent)\n",
    "    # return the sentences\n",
    "    return sentences\n",
    "\n",
    "total_sentences = convert_to_sentences(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OY0xNpssQHJh",
    "outputId": "b0424b6d-9248-4541-b62f-2f213ffe1275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314\n",
      "1314\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "# define training data\n",
    "sentences = total_sentences\n",
    "# train model\n",
    "w2v_model = Word2Vec(sentences, size=embedding_dim, min_count=1)\n",
    "# print vocab length\n",
    "print(len(w2v_model.wv.vocab))\n",
    "# get all the words\n",
    "total_words = total_tokenizer.word_index.keys()\n",
    "print(len(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oCqm8QusFNlO"
   },
   "outputs": [],
   "source": [
    "# create a dict for the word and embeddings\n",
    "vectors_dict = dict()\n",
    "# total_words is the list of words \n",
    "for key in total_words:\n",
    "    # vectors_dict is the dict of word and embeddings\n",
    "    vectors_dict[key] = w2v_model[key]\n",
    "\n",
    "#print(vectors_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCOc2G6SDxF9"
   },
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bYAmxnbsXdLZ"
   },
   "outputs": [],
   "source": [
    "# get the y col and drop the col\n",
    "Y_Data = data.IMPRESSION\n",
    "data.drop('IMPRESSION',axis = 1, inplace = True)\n",
    "\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(data, Y_Data, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Jdvm35NWctCK"
   },
   "outputs": [],
   "source": [
    "data['IMPRESSION'] = Y_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "GbE2tuLmdNZ0",
    "outputId": "697a3736-804c-47b8-bb5a-737b58774888"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>FINDINGS</th>\n",
       "      <th>IMAGES</th>\n",
       "      <th>IMAGE_FEATURE_1</th>\n",
       "      <th>IMAGE_FEATURE_2</th>\n",
       "      <th>IMPRESSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR3691</td>\n",
       "      <td>&lt;start&gt; the heart is normal in size the medias...</td>\n",
       "      <td>[CXR3691_IM-1842-1001, CXR3691_IM-1842-3003]</td>\n",
       "      <td>(tf.Tensor(0.00026685063, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(4.9858256e-05, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; no acute disease &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR3682</td>\n",
       "      <td>&lt;start&gt; the lungs are hypoventilated there is ...</td>\n",
       "      <td>[CXR3682_IM-1834-1001, CXR3682_IM-1834-2001]</td>\n",
       "      <td>(tf.Tensor(0.00033830438, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(6.356468e-05, shape=(), dtype=float...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary abnormality &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR3685</td>\n",
       "      <td>&lt;start&gt; calcified thoracic aorta mild rightwar...</td>\n",
       "      <td>[CXR3685_IM-1836-1001, CXR3685_IM-1836-1002]</td>\n",
       "      <td>(tf.Tensor(0.00016475626, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(0.0002226108, shape=(), dtype=float...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary findings &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR37</td>\n",
       "      <td>&lt;start&gt; the heart is normal in size the medias...</td>\n",
       "      <td>[CXR37_IM-1847-0001-0001, CXR37_IM-1847-0001-0...</td>\n",
       "      <td>(tf.Tensor(2.0698715e-05, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(0.00041303012, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; no acute disease &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR3703</td>\n",
       "      <td>&lt;start&gt; the eamination consists of frontal and...</td>\n",
       "      <td>[CXR3703_IM-1850-1001, CXR3703_IM-1850-2001]</td>\n",
       "      <td>(tf.Tensor(0.0003913842, shape=(), dtype=float...</td>\n",
       "      <td>(tf.Tensor(5.5506534e-06, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; no evidence of acute cardiopulmonary p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UID  ...                                         IMPRESSION\n",
       "0  CXR3691  ...                     <start> no acute disease <end>\n",
       "1  CXR3682  ...  <start> no acute cardiopulmonary abnormality <...\n",
       "2  CXR3685  ...    <start> no acute cardiopulmonary findings <end>\n",
       "3    CXR37  ...                     <start> no acute disease <end>\n",
       "4  CXR3703  ...  <start> no evidence of acute cardiopulmonary p...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efN8ks_coXWU",
    "outputId": "36eb7172-08f9-4604-87a2-98347fdcfe38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2088,)\n",
      "(522,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_Train.shape)\n",
    "print(Y_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9UmNVvojgil_",
    "outputId": "4e26cdef-9adc-494e-add9-37cf9e327f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (2088, 5) <class 'pandas.core.series.Series'> (2088,)\n",
      "<class 'pandas.core.frame.DataFrame'> (522, 5) <class 'pandas.core.series.Series'> (522,)\n",
      "checking shapes after converting y to dataframe\n",
      "<class 'pandas.core.frame.DataFrame'> (2088, 5) <class 'pandas.core.frame.DataFrame'> (2088, 1)\n",
      "<class 'pandas.core.frame.DataFrame'> (522, 5) <class 'pandas.core.frame.DataFrame'> (522, 1)\n"
     ]
    }
   ],
   "source": [
    "# get the shapes of train cv and test data\n",
    "print(type(X_Train),X_Train.shape,type(Y_Train),Y_Train.shape)\n",
    "# lets convert the Y_Train to a dataframe \n",
    "Y_DTrain = pd.DataFrame(data=Y_Train.to_list(), columns=['IMPRESSION'])\n",
    "Y_Train = Y_DTrain\n",
    "\n",
    "print(type(X_Test),X_Test.shape,type(Y_Test),Y_Test.shape)\n",
    "# lets convert the Y_Test to a dataframe\n",
    "Y_DTest = pd.DataFrame(data=Y_Test.to_list(), columns=['IMPRESSION'])\n",
    "Y_Test = Y_DTest\n",
    "\n",
    "print('checking shapes after converting y to dataframe')\n",
    "# lets again check the shapes\n",
    "print(type(X_Train),X_Train.shape,type(Y_Train),Y_Train.shape)\n",
    "print(type(X_Test),X_Test.shape,type(Y_Test),Y_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "W5x-v0cxerFJ",
    "outputId": "7a374526-9d54-4db0-ed03-2234b4fd4a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2088, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>IMAGES</th>\n",
       "      <th>IMAGE_FEATURE_1</th>\n",
       "      <th>IMAGE_FEATURE_2</th>\n",
       "      <th>FINDINGS</th>\n",
       "      <th>IMPRESSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR3755</td>\n",
       "      <td>[CXR3755_IM-1879-1001, CXR3755_IM-1879-3001]</td>\n",
       "      <td>(tf.Tensor(6.0409708e-05, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "      <td>&lt;start&gt; heart size upper limits of normal pulm...</td>\n",
       "      <td>&lt;start&gt; no acute changes from prior imaging &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR969</td>\n",
       "      <td>[CXR969_IM-2459-1001, CXR969_IM-2459-2001]</td>\n",
       "      <td>(tf.Tensor(8.086289e-05, shape=(), dtype=float...</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "      <td>&lt;start&gt; heart size upper limits of normal but ...</td>\n",
       "      <td>&lt;start&gt; no acute radiographic cardiopulmonary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR771</td>\n",
       "      <td>[CXR771_IM-2316-2001, CXR771_IM-2316-1001]</td>\n",
       "      <td>(tf.Tensor(0.0003665378, shape=(), dtype=float...</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "      <td>&lt;start&gt; heart size and pulmonary vascularity w...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary disease &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR371</td>\n",
       "      <td>[CXR371_IM-1852-1001, CXR371_IM-1852-2001]</td>\n",
       "      <td>(tf.Tensor(0.0005545218, shape=(), dtype=float...</td>\n",
       "      <td>(tf.Tensor(6.5811844e-05, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; the lungs are clear there is hyperinfl...</td>\n",
       "      <td>&lt;start&gt; copd and old granulomatous disease &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR2645</td>\n",
       "      <td>[CXR2645_IM-1131-2001, CXR2645_IM-1131-1001]</td>\n",
       "      <td>(tf.Tensor(0.00028274013, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(1.4752676e-05, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; surgical clips within the right upper ...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary abnormality &lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UID  ...                                         IMPRESSION\n",
       "0  CXR3755  ...  <start> no acute changes from prior imaging <end>\n",
       "1   CXR969  ...  <start> no acute radiographic cardiopulmonary ...\n",
       "2   CXR771  ...     <start> no acute cardiopulmonary disease <end>\n",
       "3   CXR371  ...   <start> copd and old granulomatous disease <end>\n",
       "4  CXR2645  ...  <start> no acute cardiopulmonary abnormality <...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the train dataframe\n",
    "data_train = pd.DataFrame()\n",
    "data_train['UID'] = X_Train.UID.values.tolist()\n",
    "data_train['IMAGES'] = X_Train.IMAGES.values.tolist()\n",
    "data_train['IMAGE_FEATURE_1'] = X_Train.IMAGE_FEATURE_1.values.tolist()\n",
    "data_train['IMAGE_FEATURE_2'] = X_Train.IMAGE_FEATURE_2.values.tolist()\n",
    "data_train['FINDINGS'] = X_Train.FINDINGS.values.tolist()\n",
    "data_train['IMPRESSION'] = Y_Train.IMPRESSION.values\n",
    "print(data_train.shape)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "im6lKn1YkIKI",
    "outputId": "a12e2492-16de-4c36-e54b-594411bb4fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(522, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>IMAGES</th>\n",
       "      <th>IMAGE_FEATURE_1</th>\n",
       "      <th>IMAGE_FEATURE_2</th>\n",
       "      <th>FINDINGS</th>\n",
       "      <th>IMPRESSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR2327</td>\n",
       "      <td>[CXR2327_IM-0898-1001, CXR2327_IM-0898-2001]</td>\n",
       "      <td>(tf.Tensor(0.0009207953, shape=(), dtype=float...</td>\n",
       "      <td>(tf.Tensor(8.276213e-05, shape=(), dtype=float...</td>\n",
       "      <td>&lt;start&gt; there has been interval development of...</td>\n",
       "      <td>&lt;start&gt; interval development of large rightsid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR1121</td>\n",
       "      <td>[CXR1121_IM-0080-1001, CXR1121_IM-0080-2001]</td>\n",
       "      <td>(tf.Tensor(0.00041279235, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(8.3250285e-05, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; the lungs are clear there is no pleura...</td>\n",
       "      <td>&lt;start&gt; no acute pulmonary disease &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR40</td>\n",
       "      <td>[CXR40_IM-2050-1001, CXR40_IM-2050-1002]</td>\n",
       "      <td>(tf.Tensor(0.00033369806, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(0.00030659474, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; mild hyperepansion of the lungs numero...</td>\n",
       "      <td>&lt;start&gt; emphysema with no acute cardiopulmonar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR3263</td>\n",
       "      <td>[CXR3263_IM-1549-1001, CXR3263_IM-1549-2001]</td>\n",
       "      <td>(tf.Tensor(0.00041694037, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(7.052128e-05, shape=(), dtype=float...</td>\n",
       "      <td>&lt;start&gt; chest the heart size and cardiomediast...</td>\n",
       "      <td>&lt;start&gt; chest no acute cardiopulmonary finding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR751</td>\n",
       "      <td>[CXR751_IM-2305-1001, CXR751_IM-2305-2001]</td>\n",
       "      <td>(tf.Tensor(0.000753897, shape=(), dtype=float3...</td>\n",
       "      <td>(tf.Tensor(0.00013644715, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; heart size within normal limits no foc...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary findings &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UID  ...                                         IMPRESSION\n",
       "0  CXR2327  ...  <start> interval development of large rightsid...\n",
       "1  CXR1121  ...           <start> no acute pulmonary disease <end>\n",
       "2    CXR40  ...  <start> emphysema with no acute cardiopulmonar...\n",
       "3  CXR3263  ...  <start> chest no acute cardiopulmonary finding...\n",
       "4   CXR751  ...    <start> no acute cardiopulmonary findings <end>\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the test dataframe\n",
    "data_test = pd.DataFrame()\n",
    "data_test['UID'] = X_Test.UID.values.tolist()\n",
    "data_test['IMAGES'] = X_Test.IMAGES.values.tolist()\n",
    "data_test['IMAGE_FEATURE_1'] = X_Test.IMAGE_FEATURE_1.values.tolist()\n",
    "data_test['IMAGE_FEATURE_2'] = X_Test.IMAGE_FEATURE_2.values.tolist()\n",
    "data_test['FINDINGS'] = X_Test.FINDINGS.values.tolist()\n",
    "data_test['IMPRESSION'] = Y_Test.IMPRESSION.values\n",
    "print(data_test.shape)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yD73UfVK1yb"
   },
   "source": [
    "## Data Tokenization and Making Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YCgnk26phgI",
    "outputId": "2fac1a65-368d-4ac9-b348-86f761b13700"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocab size of the impression is 573\n",
      "The maximum length of the impression is 40\n"
     ]
    }
   ],
   "source": [
    "# get the vocab for impressions\n",
    "# impression_tokenizer : tokenizer for impression\n",
    "impression_tokenizer = tensorflow.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "impression_tokenizer.fit_on_texts(data_train['IMPRESSION'])\n",
    "\n",
    "# saving tokenizer to file\n",
    "with open(drive_path + '/impression_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(impression_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "with open(drive_path + '/impression_tokenizer.pickle', 'rb') as handle:\n",
    "    impression_tokenizer = pickle.load(handle)\n",
    "\n",
    "# get the dict and save it\n",
    "impression_dict = impression_tokenizer.word_index\n",
    "\n",
    "# get the tokens\n",
    "temp_train_impression = impression_tokenizer.texts_to_sequences(data_train['IMPRESSION'])\n",
    "\n",
    "\n",
    "# Now let us get the max length of the findings\n",
    "s = []\n",
    "for d in temp_train_impression:\n",
    "    s.append(len(d))\n",
    "\n",
    "pad_length_impression = max(s)\n",
    "\n",
    "# get the vocab size\n",
    "vocab_size_impression = len(impression_tokenizer.word_index) + 1  \n",
    "\n",
    "# print max lengths\n",
    "print('The vocab size of the impression is',vocab_size_impression)\n",
    "print('The maximum length of the impression is',pad_length_impression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3enEcFQdj8x1",
    "outputId": "c7540312-34e2-4cd7-d208-4dd5343d8faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(573, 100)\n"
     ]
    }
   ],
   "source": [
    "# get the embedding matrix for the impression\n",
    "# impression_tokenizer is the tokenizer for impression\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix_impression = zeros((vocab_size_impression, embedding_dim))\n",
    "for word, i in impression_tokenizer.word_index.items():\n",
    "\tembedding_vector = vectors_dict.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix_impression[i] = embedding_vector\n",
    "\n",
    "# saving tokenizer to file\n",
    "with open(drive_path + '/embedding_matrix_impression.pickle', 'wb') as handle:\n",
    "    pickle.dump(embedding_matrix_impression, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "with open(drive_path + '/embedding_matrix_impression.pickle', 'rb') as handle:\n",
    "    embedding_matrix_impression = pickle.load(handle)\n",
    "\n",
    "\n",
    "print(embedding_matrix_impression[1].shape)\n",
    "print(embedding_matrix_impression.shape)\n",
    "\n",
    "impression_matrix = embedding_matrix_impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6KC7hzbKHsoF"
   },
   "outputs": [],
   "source": [
    "# this function will take the dataframe and return the tokenized and padded findings and impression\n",
    "def tokenize(dataset):\n",
    "    \n",
    "    impression_tensor = impression_tokenizer.texts_to_sequences(dataset.IMPRESSION)\n",
    "\n",
    "    impression_tensor = tensorflow.keras.preprocessing.sequence.pad_sequences(impression_tensor, maxlen = pad_length_impression,\n",
    "                                                         padding='post')\n",
    "\n",
    "    return impression_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "I1BlVOCmFr1P"
   },
   "outputs": [],
   "source": [
    "# this function will convert the image array into numpy\n",
    "def load_imgs(dataset):\n",
    "    img_feature_1 = dataset.IMAGE_FEATURE_1.values\n",
    "    tmp_arr_1 = np.zeros((len(img_feature_1), 1024))\n",
    "    img_feature_2 = dataset.IMAGE_FEATURE_2.values\n",
    "    tmp_arr_2 = np.zeros((len(img_feature_2), 1024))\n",
    "    #print(tmp_arr_train.shape)\n",
    "    i = 0\n",
    "    for r in img_feature_1:\n",
    "        # print(r)\n",
    "        tmp_arr_1[i] = r\n",
    "        i += 1\n",
    "\n",
    "    img_feature_1 = tmp_arr_1\n",
    "\n",
    "    i = 0\n",
    "    for r in img_feature_2:\n",
    "        # print(r)\n",
    "        tmp_arr_2[i] = r\n",
    "        i += 1\n",
    "\n",
    "    img_feature_2 = tmp_arr_2\n",
    "    \n",
    "    return img_feature_1, img_feature_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YXjjcNCGHslj"
   },
   "outputs": [],
   "source": [
    "# this function will load the cleaned images, findings and impression\n",
    "def load_dataset(dataset, purpose = 'testing'):\n",
    "    # creating cleaned input, output pairs\n",
    "    impression_tensor = tokenize(dataset)\n",
    "    img_feature_1, img_feature_2 = load_imgs(dataset)\n",
    "\n",
    "    return img_feature_1, img_feature_2, impression_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OH9-OV4fHsi8"
   },
   "outputs": [],
   "source": [
    "img_feature_1_train, img_feature_2_train, impression_tensor_train = load_dataset(data_train)\n",
    "\n",
    "# print('img_features_train', img_features_train.shape, type(img_features_train), type(img_features_train[0]))\n",
    "# print('findings_tensor_train', findings_tensor_train.shape, type(findings_tensor_train), type(findings_tensor_train[0]))\n",
    "# print('impression_tensor_train', impression_tensor_train.shape, type(impression_tensor_train), type(impression_tensor_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "EbP6Bxs3-Oco"
   },
   "outputs": [],
   "source": [
    "img_feature_1_test, img_feature_2_test, impression_tensor_test = load_dataset(data_test)\n",
    "\n",
    "# print('img_features_test', img_features_test.shape, type(img_features_test), type(img_features_test[0]))\n",
    "# print('findings_tensor_test', findings_tensor_test.shape, type(findings_tensor_test), type(findings_tensor_test[0]))\n",
    "# print('impression_tensor_test', impression_tensor_test.shape, type(impression_tensor_test), type(impression_tensor_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "0WK1l0Hk3YeR",
    "outputId": "eac2cd7f-c045-4502-df96-7111019015d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>FINDINGS</th>\n",
       "      <th>IMAGES</th>\n",
       "      <th>IMAGE_FEATURE_1</th>\n",
       "      <th>IMAGE_FEATURE_2</th>\n",
       "      <th>IMPRESSION</th>\n",
       "      <th>IMPRESSION_TOKENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR3691</td>\n",
       "      <td>&lt;start&gt; the heart is normal in size the medias...</td>\n",
       "      <td>[CXR3691_IM-1842-1001, CXR3691_IM-1842-3003]</td>\n",
       "      <td>(tf.Tensor(0.00026685063, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(4.9858256e-05, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; no acute disease &lt;end&gt;</td>\n",
       "      <td>[1, 3, 4, 6, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR3682</td>\n",
       "      <td>&lt;start&gt; the lungs are hypoventilated there is ...</td>\n",
       "      <td>[CXR3682_IM-1834-1001, CXR3682_IM-1834-2001]</td>\n",
       "      <td>(tf.Tensor(0.00033830438, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(6.356468e-05, shape=(), dtype=float...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary abnormality &lt;...</td>\n",
       "      <td>[1, 3, 4, 5, 7, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR3685</td>\n",
       "      <td>&lt;start&gt; calcified thoracic aorta mild rightwar...</td>\n",
       "      <td>[CXR3685_IM-1836-1001, CXR3685_IM-1836-1002]</td>\n",
       "      <td>(tf.Tensor(0.00016475626, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(0.0002226108, shape=(), dtype=float...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary findings &lt;end&gt;</td>\n",
       "      <td>[1, 3, 4, 5, 8, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR37</td>\n",
       "      <td>&lt;start&gt; the heart is normal in size the medias...</td>\n",
       "      <td>[CXR37_IM-1847-0001-0001, CXR37_IM-1847-0001-0...</td>\n",
       "      <td>(tf.Tensor(2.0698715e-05, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(0.00041303012, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; no acute disease &lt;end&gt;</td>\n",
       "      <td>[1, 3, 4, 6, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR3703</td>\n",
       "      <td>&lt;start&gt; the eamination consists of frontal and...</td>\n",
       "      <td>[CXR3703_IM-1850-1001, CXR3703_IM-1850-2001]</td>\n",
       "      <td>(tf.Tensor(0.0003913842, shape=(), dtype=float...</td>\n",
       "      <td>(tf.Tensor(5.5506534e-06, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; no evidence of acute cardiopulmonary p...</td>\n",
       "      <td>[1, 3, 13, 9, 4, 5, 11, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UID  ...           IMPRESSION_TOKENS\n",
       "0  CXR3691  ...             [1, 3, 4, 6, 2]\n",
       "1  CXR3682  ...          [1, 3, 4, 5, 7, 2]\n",
       "2  CXR3685  ...          [1, 3, 4, 5, 8, 2]\n",
       "3    CXR37  ...             [1, 3, 4, 6, 2]\n",
       "4  CXR3703  ...  [1, 3, 13, 9, 4, 5, 11, 2]\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the tokens to the dataframe\n",
    "data_impression_tensor = impression_tokenizer.texts_to_sequences(data.IMPRESSION)\n",
    "\n",
    "data['IMPRESSION_TOKENS'] = data_impression_tensor\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "RLTSS1sA3Yef",
    "outputId": "9d4339e9-ff1e-44cb-8daa-cad70c9cac43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>IMAGES</th>\n",
       "      <th>IMAGE_FEATURE_1</th>\n",
       "      <th>IMAGE_FEATURE_2</th>\n",
       "      <th>FINDINGS</th>\n",
       "      <th>IMPRESSION</th>\n",
       "      <th>IMPRESSION_TOKENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR3755</td>\n",
       "      <td>[CXR3755_IM-1879-1001, CXR3755_IM-1879-3001]</td>\n",
       "      <td>(tf.Tensor(6.0409708e-05, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "      <td>&lt;start&gt; heart size upper limits of normal pulm...</td>\n",
       "      <td>&lt;start&gt; no acute changes from prior imaging &lt;end&gt;</td>\n",
       "      <td>[1, 3, 4, 38, 138, 139, 156, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR969</td>\n",
       "      <td>[CXR969_IM-2459-1001, CXR969_IM-2459-2001]</td>\n",
       "      <td>(tf.Tensor(8.086289e-05, shape=(), dtype=float...</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "      <td>&lt;start&gt; heart size upper limits of normal but ...</td>\n",
       "      <td>&lt;start&gt; no acute radiographic cardiopulmonary ...</td>\n",
       "      <td>[1, 3, 4, 19, 5, 11, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR771</td>\n",
       "      <td>[CXR771_IM-2316-2001, CXR771_IM-2316-1001]</td>\n",
       "      <td>(tf.Tensor(0.0003665378, shape=(), dtype=float...</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "      <td>&lt;start&gt; heart size and pulmonary vascularity w...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary disease &lt;end&gt;</td>\n",
       "      <td>[1, 3, 4, 5, 6, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR371</td>\n",
       "      <td>[CXR371_IM-1852-1001, CXR371_IM-1852-2001]</td>\n",
       "      <td>(tf.Tensor(0.0005545218, shape=(), dtype=float...</td>\n",
       "      <td>(tf.Tensor(6.5811844e-05, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; the lungs are clear there is hyperinfl...</td>\n",
       "      <td>&lt;start&gt; copd and old granulomatous disease &lt;end&gt;</td>\n",
       "      <td>[1, 63, 23, 169, 122, 6, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR2645</td>\n",
       "      <td>[CXR2645_IM-1131-2001, CXR2645_IM-1131-1001]</td>\n",
       "      <td>(tf.Tensor(0.00028274013, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(1.4752676e-05, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; surgical clips within the right upper ...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary abnormality &lt;...</td>\n",
       "      <td>[1, 3, 4, 5, 7, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UID  ...                IMPRESSION_TOKENS\n",
       "0  CXR3755  ...  [1, 3, 4, 38, 138, 139, 156, 2]\n",
       "1   CXR969  ...          [1, 3, 4, 19, 5, 11, 2]\n",
       "2   CXR771  ...               [1, 3, 4, 5, 6, 2]\n",
       "3   CXR371  ...      [1, 63, 23, 169, 122, 6, 2]\n",
       "4  CXR2645  ...               [1, 3, 4, 5, 7, 2]\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the tokens to the dataframe\n",
    "data_train_impression_tensor = impression_tokenizer.texts_to_sequences(data_train.IMPRESSION)\n",
    "\n",
    "data_train['IMPRESSION_TOKENS'] = data_train_impression_tensor\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "YqWcRpWQ3Yep",
    "outputId": "1d222e79-a9fa-4d9f-c8b6-f0b7e586739a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>IMAGES</th>\n",
       "      <th>IMAGE_FEATURE_1</th>\n",
       "      <th>IMAGE_FEATURE_2</th>\n",
       "      <th>FINDINGS</th>\n",
       "      <th>IMPRESSION</th>\n",
       "      <th>IMPRESSION_TOKENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR2327</td>\n",
       "      <td>[CXR2327_IM-0898-1001, CXR2327_IM-0898-2001]</td>\n",
       "      <td>(tf.Tensor(0.0009207953, shape=(), dtype=float...</td>\n",
       "      <td>(tf.Tensor(8.276213e-05, shape=(), dtype=float...</td>\n",
       "      <td>&lt;start&gt; there has been interval development of...</td>\n",
       "      <td>&lt;start&gt; interval development of large rightsid...</td>\n",
       "      <td>[1, 84, 563, 9, 135, 285, 32, 55, 518, 118, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR1121</td>\n",
       "      <td>[CXR1121_IM-0080-1001, CXR1121_IM-0080-2001]</td>\n",
       "      <td>(tf.Tensor(0.00041279235, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(8.3250285e-05, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; the lungs are clear there is no pleura...</td>\n",
       "      <td>&lt;start&gt; no acute pulmonary disease &lt;end&gt;</td>\n",
       "      <td>[1, 3, 4, 12, 6, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR40</td>\n",
       "      <td>[CXR40_IM-2050-1001, CXR40_IM-2050-1002]</td>\n",
       "      <td>(tf.Tensor(0.00033369806, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(0.00030659474, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; mild hyperepansion of the lungs numero...</td>\n",
       "      <td>&lt;start&gt; emphysema with no acute cardiopulmonar...</td>\n",
       "      <td>[1, 71, 14, 3, 4, 5, 8, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR3263</td>\n",
       "      <td>[CXR3263_IM-1549-1001, CXR3263_IM-1549-2001]</td>\n",
       "      <td>(tf.Tensor(0.00041694037, shape=(), dtype=floa...</td>\n",
       "      <td>(tf.Tensor(7.052128e-05, shape=(), dtype=float...</td>\n",
       "      <td>&lt;start&gt; chest the heart size and cardiomediast...</td>\n",
       "      <td>&lt;start&gt; chest no acute cardiopulmonary finding...</td>\n",
       "      <td>[1, 15, 3, 4, 5, 61, 25, 559, 72, 560, 38, 274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR751</td>\n",
       "      <td>[CXR751_IM-2305-1001, CXR751_IM-2305-2001]</td>\n",
       "      <td>(tf.Tensor(0.000753897, shape=(), dtype=float3...</td>\n",
       "      <td>(tf.Tensor(0.00013644715, shape=(), dtype=floa...</td>\n",
       "      <td>&lt;start&gt; heart size within normal limits no foc...</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary findings &lt;end&gt;</td>\n",
       "      <td>[1, 3, 4, 5, 8, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UID  ...                                  IMPRESSION_TOKENS\n",
       "0  CXR2327  ...  [1, 84, 563, 9, 135, 285, 32, 55, 518, 118, 21...\n",
       "1  CXR1121  ...                                [1, 3, 4, 12, 6, 2]\n",
       "2    CXR40  ...                         [1, 71, 14, 3, 4, 5, 8, 2]\n",
       "3  CXR3263  ...  [1, 15, 3, 4, 5, 61, 25, 559, 72, 560, 38, 274...\n",
       "4   CXR751  ...                                 [1, 3, 4, 5, 8, 2]\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the tokens to the dataframe\n",
    "data_test_impression_tensor = impression_tokenizer.texts_to_sequences(data_test.IMPRESSION)\n",
    "\n",
    "data_test['IMPRESSION_TOKENS'] = data_test_impression_tensor\n",
    "\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDZ9xyqLrUVt",
    "outputId": "6ab59b8a-145d-45f9-ddae-31bf6a9069dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length  2088\n",
      "test length 522\n"
     ]
    }
   ],
   "source": [
    "print('train length ', impression_tensor_train.shape[0])\n",
    "print('test length', impression_tensor_test.shape[0])\n",
    "\n",
    "train_len = impression_tensor_train.shape[0]\n",
    "test_len = impression_tensor_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRv0yaBb_yQm"
   },
   "source": [
    "## Encoder Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "syRmCCEfOVOu"
   },
   "outputs": [],
   "source": [
    "# setting some vartables\n",
    "BUFFER_SIZE = len(impression_tensor_train)\n",
    "BATCH_SIZE = 128\n",
    "steps_per_epoch = len(impression_tensor_train)//BATCH_SIZE\n",
    "units = 256\n",
    "vocab_tar_size = len(impression_tokenizer.word_index)+1\n",
    "\n",
    "# creating the tensorflow datasets\n",
    "dataset_train = tensorflow.data.Dataset.from_tensor_slices((img_feature_1_train, img_feature_2_train, impression_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_test = tensorflow.data.Dataset.from_tensor_slices((img_feature_1_test, img_feature_2_test, impression_tensor_test)).shuffle(BUFFER_SIZE)\n",
    "dataset_test = dataset_test.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zfzZge0OVLU",
    "outputId": "5c779950-c024-42a6-c3e4-5e9acb8b9f33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 1024]), TensorShape([128, 1024]), TensorShape([128, 40]))"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the example batch shapes\n",
    "example_img1_batch, example_img2_batch, example_target_batch = next(iter(dataset_train))\n",
    "example_img1_batch.shape ,example_img2_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3N3K8AYZpG3G"
   },
   "source": [
    "### X-Ray Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "6QIH6Y-rHTF4"
   },
   "outputs": [],
   "source": [
    "# this class is for the x-ray features encoder \n",
    "class Encoder_Xray(tensorflow.keras.Model):\n",
    "    # Since you have already extracted the features and dumped it using pickle\n",
    "    # This encoder passes those features through a Fully connected layer\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(Encoder_Xray, self).__init__()\n",
    "        # shape after fc == (batch_size, 64, embedding_dim)\n",
    "        self.fc = tensorflow.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = tensorflow.nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBH0zteipXyt"
   },
   "source": [
    "### X-Ray Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "x3veJKZ2Hywa"
   },
   "outputs": [],
   "source": [
    "# this class is for the xray features Attention\n",
    "class BahdanauAttention_Xray(tensorflow.keras.Model):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention_Xray, self).__init__()\n",
    "    self.W1 = tensorflow.keras.layers.Dense(units)\n",
    "    self.W2 = tensorflow.keras.layers.Dense(units)\n",
    "    self.W3 = tensorflow.keras.layers.Dense(units)\n",
    "    self.W4 = tensorflow.keras.layers.Dense(units)\n",
    "    self.V = tensorflow.keras.layers.Dense(1)\n",
    "    self.add = tensorflow.keras.layers.Add()\n",
    "\n",
    "  def call(self, features, hidden):\n",
    "    # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n",
    "    # hidden shape == (batch_size, hidden_size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
    "    hidden_with_time_axis = tensorflow.expand_dims(hidden, 1)\n",
    "    # score shape == (batch_size, 64, hidden_size)\n",
    "    score = tensorflow.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "    # attention_weights shape == (batch_size, 64, 1)\n",
    "    # you get 1 at the last axis because you are applying score to self.V\n",
    "    attention_weights = tensorflow.nn.softmax(self.V(score), axis=1)\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * features\n",
    "    context_vector = tensorflow.reduce_sum(context_vector, axis=1)\n",
    "    return context_vector, attention_weights\n",
    "# this class is for the decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkhhSBo8pcL-"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KMpY7i3AUrI4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tensorflow.keras.Model):\n",
    "    def __init__(self, embedding_dim, units, vocab_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embedding = tensorflow.keras.layers.Embedding(vocab_size, embedding_dim, weights=[impression_matrix], mask_zero=True)\n",
    "        self.gru = tensorflow.keras.layers.GRU(self.units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "        self.fc1 = tensorflow.keras.layers.Dense(self.units, activation='relu')\n",
    "        self.fc2 = tensorflow.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention1 = BahdanauAttention_Xray(self.units)\n",
    "        self.attention2 = BahdanauAttention_Xray(self.units)\n",
    "\n",
    "\n",
    "    def call(self, x = np.zeros((1,1)), features1 = np.zeros((1,100)), features2 = np.zeros((1,100)), hidden = np.zeros((1,256))):\n",
    "        # defining attention as a separate model\n",
    "        context_vector1, attention_weights1 = self.attention1(features1, hidden)\n",
    "        context_vector2, attention_weights2 = self.attention2(features2, hidden)\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        x = tensorflow.concat([tensorflow.expand_dims(context_vector1, 1), tensorflow.expand_dims(context_vector2, 1), x], axis=-1)\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        # shape == (batch_size, max_length, hidden_size)\n",
    "        x = self.fc1(output)\n",
    "        # x_shape == (batch_size * max_length, hidden_size)\n",
    "        x = tensorflow.reshape(x, (-1, x.shape[2]))\n",
    "        # output_shape == (batch_size * max_length, vocab)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, state\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        return tensorflow.zeros((batch_size, self.units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbYXA-XLpfPd"
   },
   "source": [
    "### Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "iTW4tgh4VR3u"
   },
   "outputs": [],
   "source": [
    "# initializing the optimizer and the loss function\n",
    "optimizer = tensorflow.keras.optimizers.Adam(0.01)\n",
    "loss_object = tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # get the mask\n",
    "    mask = tensorflow.math.logical_not(tensorflow.math.equal(real, 0))\n",
    "    # calculate loss\n",
    "    loss_ = loss_object(real, pred)\n",
    "    # cast mask\n",
    "    mask = tensorflow.cast(mask, dtype=loss_.dtype)\n",
    "    # loss = loss * mask\n",
    "    loss_ *= mask\n",
    "    # normalize loss\n",
    "    loss_ /= pad_length_impression\n",
    "    # calculate mean and return loss\n",
    "    return tensorflow.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kH7_z9e1yRXD"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "APR5tS41yOtI"
   },
   "outputs": [],
   "source": [
    "# initialize model\n",
    "encoder1 = Encoder_Xray(embedding_dim)\n",
    "encoder2 = Encoder_Xray(embedding_dim)\n",
    "decoder = Decoder(embedding_dim, units, vocab_tar_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2xtdTYPWVRyU"
   },
   "outputs": [],
   "source": [
    "@tensorflow.function\n",
    "def train_step(img_tensor1, img_tensor2, target):\n",
    "    # initialize loss\n",
    "    loss = 0\n",
    "\n",
    "    # initializing the hidden state for each batch\n",
    "    # because the impressions are not related from image to image\n",
    "    hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "    # put the first input\n",
    "    dec_input = tensorflow.expand_dims([impression_tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
    "    # using gradient taping\n",
    "    with tensorflow.GradientTape() as tape:\n",
    "        # get image features\n",
    "        features1 = encoder1(img_tensor1)\n",
    "        features2 = encoder2(img_tensor2)\n",
    "        # loop over all the words in the impression\n",
    "        for i in range(1, target.shape[1]):\n",
    "            # get the predections\n",
    "            predictions, hidden = decoder(dec_input, features1, features2, hidden)\n",
    "            # calculate loss\n",
    "            loss += loss_function(target[:, i], predictions)\n",
    "            # using teacher forcing\n",
    "            dec_input = tensorflow.expand_dims(target[:, i], 1)\n",
    "            #print(dec_input.shape)\n",
    "    total_loss = loss \n",
    "    # get trainable variables\n",
    "    trainable_variables = encoder1.trainable_variables + encoder2.trainable_variables + decoder.trainable_variables\n",
    "    # get gradients\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "    # apply gradients\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "    # return loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "# function to calculate blue score\n",
    "def calc_blue(img1, img2, target):\n",
    "    # initializing the hidden state for each batch\n",
    "    # because the impressions are not related from image to image\n",
    "    hidden = decoder.reset_state(batch_size=1)\n",
    "\n",
    "    # reshape image features\n",
    "    img1 = tensorflow.keras.backend.reshape(img1, shape=(1, -1))\n",
    "    img2 = tensorflow.keras.backend.reshape(img2, shape=(1, -1))\n",
    "    # get the target sentence\n",
    "    target_sent = list()\n",
    "    for t in target:\n",
    "        target_sent.append(impression_tokenizer.index_word[t])\n",
    "    # get image features\n",
    "    features1 = encoder1(img1)\n",
    "    features2 = encoder2(img2)\n",
    "    # initial decoder input\n",
    "    dec_input = tensorflow.expand_dims([impression_tokenizer.word_index['<start>']], 0)\n",
    "    # initialize the result array\n",
    "    result = []\n",
    "    result.append('<start>')\n",
    "    # loop for the entire pad lenght\n",
    "    for i in range(pad_length_impression):\n",
    "        # predict\n",
    "        predictions, hidden = decoder(dec_input, features1, features2, hidden)\n",
    "\n",
    "        # calculate max\n",
    "        predicted_id = predictions.numpy().argmax()\n",
    "        # append the predicted word to result array\n",
    "        result.append(impression_tokenizer.index_word[predicted_id])\n",
    "        # if '<end>' is reached\n",
    "        if impression_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            # calculate bleu score and return\n",
    "            score = sentence_bleu([target_sent], result)\n",
    "            return score\n",
    "        # the next input to the model is predected at this step\n",
    "        dec_input = tensorflow.expand_dims([predicted_id], 0)\n",
    "        \n",
    "    # calculate score at the end and return it\n",
    "    score = sentence_bleu([target_sent], result)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3d3u7SYVq9M",
    "outputId": "524d7151-01fb-464c-92a9-c2eabd4596ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer encoder__xray is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer encoder__xray_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1 Training Loss 0.764666\n",
      "Time taken for 1 epoch 43.1100537776947 sec\n",
      "\n",
      "Epoch 2 Training Loss 0.678342\n",
      "Time taken for 1 epoch 1.7557966709136963 sec\n",
      "\n",
      "Epoch 3 Training Loss 0.619599\n",
      "Time taken for 1 epoch 1.751091480255127 sec\n",
      "\n",
      "Epoch 4 Training Loss 0.571592\n",
      "Time taken for 1 epoch 1.75447416305542 sec\n",
      "\n",
      "Epoch 5 Training Loss 0.535569\n",
      "Time taken for 1 epoch 1.7518906593322754 sec\n",
      "\n",
      "Epoch 6 Training Loss 0.506147\n",
      "Time taken for 1 epoch 1.7537760734558105 sec\n",
      "\n",
      "Epoch 7 Training Loss 0.481773\n",
      "Time taken for 1 epoch 1.7411863803863525 sec\n",
      "\n",
      "Epoch 8 Training Loss 0.461111\n",
      "Time taken for 1 epoch 1.743906021118164 sec\n",
      "\n",
      "Epoch 9 Training Loss 0.443273\n",
      "Time taken for 1 epoch 1.7468461990356445 sec\n",
      "\n",
      "Epoch 10 Training Loss 0.428080\n",
      "Time taken for 1 epoch 1.7506556510925293 sec\n",
      "\n",
      "Epoch 11 Training Loss 0.414714\n",
      "Time taken for 1 epoch 1.745523452758789 sec\n",
      "\n",
      "Epoch 12 Training Loss 0.402844\n",
      "Time taken for 1 epoch 1.734950065612793 sec\n",
      "\n",
      "Epoch 13 Training Loss 0.392088\n",
      "Time taken for 1 epoch 1.7389094829559326 sec\n",
      "\n",
      "Epoch 14 Training Loss 0.382464\n",
      "Time taken for 1 epoch 1.7329418659210205 sec\n",
      "\n",
      "Epoch 15 Training Loss 0.373770\n",
      "Time taken for 1 epoch 1.7397570610046387 sec\n",
      "\n",
      "Epoch 16 Training Loss 0.365853\n",
      "Time taken for 1 epoch 1.7428815364837646 sec\n",
      "\n",
      "Epoch 17 Training Loss 0.358573\n",
      "Time taken for 1 epoch 1.7351703643798828 sec\n",
      "\n",
      "Epoch 18 Training Loss 0.351798\n",
      "Time taken for 1 epoch 1.7464091777801514 sec\n",
      "\n",
      "Epoch 19 Training Loss 0.345711\n",
      "Time taken for 1 epoch 1.7794032096862793 sec\n",
      "\n",
      "Epoch 20 Training Loss 0.339943\n",
      "Time taken for 1 epoch 1.749382495880127 sec\n",
      "\n",
      "Epoch 21 Training Loss 0.334664\n",
      "Time taken for 1 epoch 1.7510864734649658 sec\n",
      "\n",
      "Epoch 22 Training Loss 0.329708\n",
      "Time taken for 1 epoch 1.7493853569030762 sec\n",
      "\n",
      "Epoch 23 Training Loss 0.324977\n",
      "Time taken for 1 epoch 1.7577123641967773 sec\n",
      "\n",
      "Epoch 24 Training Loss 0.320652\n",
      "Time taken for 1 epoch 1.768519401550293 sec\n",
      "\n",
      "Epoch 25 Training Loss 0.316569\n",
      "Time taken for 1 epoch 1.7496285438537598 sec\n",
      "\n",
      "Epoch 26 Training Loss 0.312682\n",
      "Time taken for 1 epoch 1.7562282085418701 sec\n",
      "\n",
      "Epoch 27 Training Loss 0.309069\n",
      "Time taken for 1 epoch 1.7483093738555908 sec\n",
      "\n",
      "Epoch 28 Training Loss 0.305651\n",
      "Time taken for 1 epoch 1.7548182010650635 sec\n",
      "\n",
      "Epoch 29 Training Loss 0.302282\n",
      "Time taken for 1 epoch 1.7486851215362549 sec\n",
      "\n",
      "Epoch 30 Training Loss 0.299032\n",
      "Time taken for 1 epoch 1.7423696517944336 sec\n",
      "\n",
      "Epoch 31 Training Loss 0.295965\n",
      "Time taken for 1 epoch 1.7453885078430176 sec\n",
      "\n",
      "Epoch 32 Training Loss 0.293106\n",
      "Time taken for 1 epoch 1.7446696758270264 sec\n",
      "\n",
      "Epoch 33 Training Loss 0.290296\n",
      "Time taken for 1 epoch 1.7439594268798828 sec\n",
      "\n",
      "Epoch 34 Training Loss 0.287661\n",
      "Time taken for 1 epoch 1.7400922775268555 sec\n",
      "\n",
      "Epoch 35 Training Loss 0.285120\n",
      "Time taken for 1 epoch 1.74664306640625 sec\n",
      "\n",
      "Epoch 36 Training Loss 0.282719\n",
      "Time taken for 1 epoch 1.7424383163452148 sec\n",
      "\n",
      "Epoch 37 Training Loss 0.280367\n",
      "Time taken for 1 epoch 1.7513728141784668 sec\n",
      "\n",
      "Epoch 38 Training Loss 0.278164\n",
      "Time taken for 1 epoch 1.7347412109375 sec\n",
      "\n",
      "Epoch 39 Training Loss 0.276010\n",
      "Time taken for 1 epoch 1.751239538192749 sec\n",
      "\n",
      "Epoch 40 Training Loss 0.273912\n",
      "Time taken for 1 epoch 1.7229094505310059 sec\n",
      "\n",
      "Epoch 41 Training Loss 0.271930\n",
      "Time taken for 1 epoch 1.7430145740509033 sec\n",
      "\n",
      "Epoch 42 Training Loss 0.270010\n",
      "Time taken for 1 epoch 1.7489478588104248 sec\n",
      "\n",
      "Epoch 43 Training Loss 0.268158\n",
      "Time taken for 1 epoch 1.7261481285095215 sec\n",
      "\n",
      "Epoch 44 Training Loss 0.266386\n",
      "Time taken for 1 epoch 1.7278873920440674 sec\n",
      "\n",
      "Epoch 45 Training Loss 0.264700\n",
      "Time taken for 1 epoch 1.7466158866882324 sec\n",
      "\n",
      "Epoch 46 Training Loss 0.263033\n",
      "Time taken for 1 epoch 1.733468770980835 sec\n",
      "\n",
      "Epoch 47 Training Loss 0.261393\n",
      "Time taken for 1 epoch 1.735180377960205 sec\n",
      "\n",
      "Epoch 48 Training Loss 0.259801\n",
      "Time taken for 1 epoch 1.747366189956665 sec\n",
      "\n",
      "Epoch 49 Training Loss 0.258225\n",
      "Time taken for 1 epoch 1.730334758758545 sec\n",
      "\n",
      "Epoch 50 Training Loss 0.256712\n",
      "Time taken for 1 epoch 1.745051383972168 sec\n",
      "\n",
      "Epoch 51 Training Loss 0.255227\n",
      "Time taken for 1 epoch 1.7265064716339111 sec\n",
      "\n",
      "Epoch 52 Training Loss 0.253860\n",
      "Time taken for 1 epoch 1.7525529861450195 sec\n",
      "\n",
      "Epoch 53 Training Loss 0.252487\n",
      "Time taken for 1 epoch 1.727830410003662 sec\n",
      "\n",
      "Epoch 54 Training Loss 0.251128\n",
      "Time taken for 1 epoch 1.7372243404388428 sec\n",
      "\n",
      "Epoch 55 Training Loss 0.249762\n",
      "Time taken for 1 epoch 1.736968994140625 sec\n",
      "\n",
      "Epoch 56 Training Loss 0.248477\n",
      "Time taken for 1 epoch 1.7417497634887695 sec\n",
      "\n",
      "Epoch 57 Training Loss 0.247324\n",
      "Time taken for 1 epoch 1.7258658409118652 sec\n",
      "\n",
      "Epoch 58 Training Loss 0.246162\n",
      "Time taken for 1 epoch 1.7300522327423096 sec\n",
      "\n",
      "Epoch 59 Training Loss 0.245027\n",
      "Time taken for 1 epoch 1.7329480648040771 sec\n",
      "\n",
      "Epoch 60 Training Loss 0.243904\n",
      "Time taken for 1 epoch 1.7443952560424805 sec\n",
      "\n",
      "Epoch 61 Training Loss 0.242814\n",
      "Time taken for 1 epoch 1.7585082054138184 sec\n",
      "\n",
      "Epoch 62 Training Loss 0.241740\n",
      "Time taken for 1 epoch 1.7393877506256104 sec\n",
      "\n",
      "Epoch 63 Training Loss 0.240735\n",
      "Time taken for 1 epoch 1.7401008605957031 sec\n",
      "\n",
      "Epoch 64 Training Loss 0.239849\n",
      "Time taken for 1 epoch 1.7213726043701172 sec\n",
      "\n",
      "Epoch 65 Training Loss 0.238926\n",
      "Time taken for 1 epoch 1.7284631729125977 sec\n",
      "\n",
      "Epoch 66 Training Loss 0.237974\n",
      "Time taken for 1 epoch 1.7268953323364258 sec\n",
      "\n",
      "Epoch 67 Training Loss 0.237006\n",
      "Time taken for 1 epoch 1.741189956665039 sec\n",
      "\n",
      "Epoch 68 Training Loss 0.236150\n",
      "Time taken for 1 epoch 1.7454450130462646 sec\n",
      "\n",
      "Epoch 69 Training Loss 0.235469\n",
      "Time taken for 1 epoch 1.7382800579071045 sec\n",
      "\n",
      "Epoch 70 Training Loss 0.234640\n",
      "Time taken for 1 epoch 1.72660231590271 sec\n",
      "\n",
      "Epoch 71 Training Loss 0.233801\n",
      "Time taken for 1 epoch 1.7175319194793701 sec\n",
      "\n",
      "Epoch 72 Training Loss 0.232954\n",
      "Time taken for 1 epoch 1.7255513668060303 sec\n",
      "\n",
      "Epoch 73 Training Loss 0.232091\n",
      "Time taken for 1 epoch 1.7302367687225342 sec\n",
      "\n",
      "Epoch 74 Training Loss 0.231245\n",
      "Time taken for 1 epoch 1.7275335788726807 sec\n",
      "\n",
      "Epoch 75 Training Loss 0.230421\n",
      "Time taken for 1 epoch 1.7236242294311523 sec\n",
      "\n",
      "Epoch 76 Training Loss 0.229575\n",
      "Time taken for 1 epoch 1.7176399230957031 sec\n",
      "\n",
      "Epoch 77 Training Loss 0.228736\n",
      "Time taken for 1 epoch 1.7320003509521484 sec\n",
      "\n",
      "Epoch 78 Training Loss 0.227906\n",
      "Time taken for 1 epoch 1.7297275066375732 sec\n",
      "\n",
      "Epoch 79 Training Loss 0.227108\n",
      "Time taken for 1 epoch 1.739776611328125 sec\n",
      "\n",
      "Epoch 80 Training Loss 0.226328\n",
      "Time taken for 1 epoch 1.7388312816619873 sec\n",
      "\n",
      "Epoch 81 Training Loss 0.225561\n",
      "Time taken for 1 epoch 1.7200608253479004 sec\n",
      "\n",
      "Epoch 82 Training Loss 0.224809\n",
      "Time taken for 1 epoch 1.7148046493530273 sec\n",
      "\n",
      "Epoch 83 Training Loss 0.224060\n",
      "Time taken for 1 epoch 1.7183818817138672 sec\n",
      "\n",
      "Epoch 84 Training Loss 0.223325\n",
      "Time taken for 1 epoch 1.734701156616211 sec\n",
      "\n",
      "Epoch 85 Training Loss 0.222605\n",
      "Time taken for 1 epoch 1.7352662086486816 sec\n",
      "\n",
      "Epoch 86 Training Loss 0.221923\n",
      "Time taken for 1 epoch 1.7319996356964111 sec\n",
      "\n",
      "Epoch 87 Training Loss 0.221256\n",
      "Time taken for 1 epoch 1.7256431579589844 sec\n",
      "\n",
      "Epoch 88 Training Loss 0.220635\n",
      "Time taken for 1 epoch 1.7368271350860596 sec\n",
      "\n",
      "Epoch 89 Training Loss 0.220088\n",
      "Time taken for 1 epoch 1.7268929481506348 sec\n",
      "\n",
      "Epoch 90 Training Loss 0.219539\n",
      "Time taken for 1 epoch 1.741262435913086 sec\n",
      "\n",
      "Epoch 91 Training Loss 0.218956\n",
      "Time taken for 1 epoch 1.7410778999328613 sec\n",
      "\n",
      "Epoch 92 Training Loss 0.218370\n",
      "Time taken for 1 epoch 1.7291529178619385 sec\n",
      "\n",
      "Epoch 93 Training Loss 0.217828\n",
      "Time taken for 1 epoch 1.7432618141174316 sec\n",
      "\n",
      "Epoch 94 Training Loss 0.217291\n",
      "Time taken for 1 epoch 1.7419376373291016 sec\n",
      "\n",
      "Epoch 95 Training Loss 0.216732\n",
      "Time taken for 1 epoch 1.7362146377563477 sec\n",
      "\n",
      "Epoch 96 Training Loss 0.216155\n",
      "Time taken for 1 epoch 1.7466895580291748 sec\n",
      "\n",
      "Epoch 97 Training Loss 0.215576\n",
      "Time taken for 1 epoch 1.7403905391693115 sec\n",
      "\n",
      "Epoch 98 Training Loss 0.215001\n",
      "Time taken for 1 epoch 1.7296957969665527 sec\n",
      "\n",
      "Epoch 99 Training Loss 0.214438\n",
      "Time taken for 1 epoch 1.73065185546875 sec\n",
      "\n",
      "Epoch 100 Training Loss 0.213876\n",
      "Time taken for 1 epoch 1.7120766639709473 sec\n",
      "\n",
      "Epoch 101 Training Loss 0.213314\n",
      "Time taken for 1 epoch 1.7337963581085205 sec\n",
      "\n",
      "Epoch 102 Training Loss 0.212762\n",
      "Time taken for 1 epoch 1.7289888858795166 sec\n",
      "\n",
      "Epoch 103 Training Loss 0.212226\n",
      "Time taken for 1 epoch 1.738152027130127 sec\n",
      "\n",
      "Epoch 104 Training Loss 0.211687\n",
      "Time taken for 1 epoch 1.7356548309326172 sec\n",
      "\n",
      "Epoch 105 Training Loss 0.211168\n",
      "Time taken for 1 epoch 1.725252628326416 sec\n",
      "\n",
      "Epoch 106 Training Loss 0.210663\n",
      "Time taken for 1 epoch 1.7370333671569824 sec\n",
      "\n",
      "Epoch 107 Training Loss 0.210179\n",
      "Time taken for 1 epoch 1.7185380458831787 sec\n",
      "\n",
      "Epoch 108 Training Loss 0.209743\n",
      "Time taken for 1 epoch 1.7386536598205566 sec\n",
      "\n",
      "Epoch 109 Training Loss 0.209320\n",
      "Time taken for 1 epoch 1.7282788753509521 sec\n",
      "\n",
      "Epoch 110 Training Loss 0.208973\n",
      "Time taken for 1 epoch 1.7218620777130127 sec\n",
      "\n",
      "Epoch 111 Training Loss 0.208649\n",
      "Time taken for 1 epoch 1.7141950130462646 sec\n",
      "\n",
      "Epoch 112 Training Loss 0.208286\n",
      "Time taken for 1 epoch 1.7131149768829346 sec\n",
      "\n",
      "Epoch 113 Training Loss 0.207913\n",
      "Time taken for 1 epoch 1.7481863498687744 sec\n",
      "\n",
      "Epoch 114 Training Loss 0.207521\n",
      "Time taken for 1 epoch 1.7222018241882324 sec\n",
      "\n",
      "Epoch 115 Training Loss 0.207136\n",
      "Time taken for 1 epoch 1.7457780838012695 sec\n",
      "\n",
      "Epoch 116 Training Loss 0.206777\n",
      "Time taken for 1 epoch 1.7115511894226074 sec\n",
      "\n",
      "Epoch 117 Training Loss 0.206411\n",
      "Time taken for 1 epoch 1.7262368202209473 sec\n",
      "\n",
      "Epoch 118 Training Loss 0.206022\n",
      "Time taken for 1 epoch 1.7171101570129395 sec\n",
      "\n",
      "Epoch 119 Training Loss 0.205620\n",
      "Time taken for 1 epoch 1.7168903350830078 sec\n",
      "\n",
      "Epoch 120 Training Loss 0.205215\n",
      "Time taken for 1 epoch 1.7237980365753174 sec\n",
      "\n",
      "Epoch 121 Training Loss 0.204815\n",
      "Time taken for 1 epoch 1.7281270027160645 sec\n",
      "\n",
      "Epoch 122 Training Loss 0.204431\n",
      "Time taken for 1 epoch 1.719010353088379 sec\n",
      "\n",
      "Epoch 123 Training Loss 0.204051\n",
      "Time taken for 1 epoch 1.7328522205352783 sec\n",
      "\n",
      "Epoch 124 Training Loss 0.203666\n",
      "Time taken for 1 epoch 1.7581958770751953 sec\n",
      "\n",
      "Epoch 125 Training Loss 0.203297\n",
      "Time taken for 1 epoch 1.7353789806365967 sec\n",
      "\n",
      "Epoch 126 Training Loss 0.202971\n",
      "Time taken for 1 epoch 1.7074527740478516 sec\n",
      "\n",
      "Epoch 127 Training Loss 0.202679\n",
      "Time taken for 1 epoch 1.7370340824127197 sec\n",
      "\n",
      "Epoch 128 Training Loss 0.202397\n",
      "Time taken for 1 epoch 1.7209858894348145 sec\n",
      "\n",
      "Epoch 129 Training Loss 0.202132\n",
      "Time taken for 1 epoch 1.7440063953399658 sec\n",
      "\n",
      "Epoch 130 Training Loss 0.201859\n",
      "Time taken for 1 epoch 1.73471999168396 sec\n",
      "\n",
      "Epoch 131 Training Loss 0.201556\n",
      "Time taken for 1 epoch 1.724520206451416 sec\n",
      "\n",
      "Epoch 132 Training Loss 0.201234\n",
      "Time taken for 1 epoch 1.7444090843200684 sec\n",
      "\n",
      "Epoch 133 Training Loss 0.200911\n",
      "Time taken for 1 epoch 1.7283194065093994 sec\n",
      "\n",
      "Epoch 134 Training Loss 0.200579\n",
      "Time taken for 1 epoch 1.7180938720703125 sec\n",
      "\n",
      "Epoch 135 Training Loss 0.200245\n",
      "Time taken for 1 epoch 1.7362937927246094 sec\n",
      "\n",
      "Epoch 136 Training Loss 0.199905\n",
      "Time taken for 1 epoch 1.7151923179626465 sec\n",
      "\n",
      "Epoch 137 Training Loss 0.199569\n",
      "Time taken for 1 epoch 1.7182338237762451 sec\n",
      "\n",
      "Epoch 138 Training Loss 0.199238\n",
      "Time taken for 1 epoch 1.7367796897888184 sec\n",
      "\n",
      "Epoch 139 Training Loss 0.198923\n",
      "Time taken for 1 epoch 1.7180507183074951 sec\n",
      "\n",
      "Epoch 140 Training Loss 0.198600\n",
      "Time taken for 1 epoch 1.748206377029419 sec\n",
      "\n",
      "Epoch 141 Training Loss 0.198278\n",
      "Time taken for 1 epoch 1.7205727100372314 sec\n",
      "\n",
      "Epoch 142 Training Loss 0.197980\n",
      "Time taken for 1 epoch 1.7366936206817627 sec\n",
      "\n",
      "Epoch 143 Training Loss 0.197778\n",
      "Time taken for 1 epoch 1.7323999404907227 sec\n",
      "\n",
      "Epoch 144 Training Loss 0.197541\n",
      "Time taken for 1 epoch 1.7331762313842773 sec\n",
      "\n",
      "Epoch 145 Training Loss 0.197277\n",
      "Time taken for 1 epoch 1.724501371383667 sec\n",
      "\n",
      "Epoch 146 Training Loss 0.196993\n",
      "Time taken for 1 epoch 1.7296690940856934 sec\n",
      "\n",
      "Epoch 147 Training Loss 0.196702\n",
      "Time taken for 1 epoch 1.711646556854248 sec\n",
      "\n",
      "Epoch 148 Training Loss 0.196422\n",
      "Time taken for 1 epoch 1.7187767028808594 sec\n",
      "\n",
      "Epoch 149 Training Loss 0.196157\n",
      "Time taken for 1 epoch 1.7147321701049805 sec\n",
      "\n",
      "Epoch 150 Training Loss 0.195881\n",
      "Time taken for 1 epoch 1.7234210968017578 sec\n",
      "\n",
      "Epoch 151 Training Loss 0.195601\n",
      "Time taken for 1 epoch 1.7222275733947754 sec\n",
      "\n",
      "Epoch 152 Training Loss 0.195313\n",
      "Time taken for 1 epoch 1.7224071025848389 sec\n",
      "\n",
      "Epoch 153 Training Loss 0.195029\n",
      "Time taken for 1 epoch 1.71073317527771 sec\n",
      "\n",
      "Epoch 154 Training Loss 0.194761\n",
      "Time taken for 1 epoch 1.7190659046173096 sec\n",
      "\n",
      "Epoch 155 Training Loss 0.194475\n",
      "Time taken for 1 epoch 1.7173917293548584 sec\n",
      "\n",
      "Epoch 156 Training Loss 0.194198\n",
      "Time taken for 1 epoch 1.7137787342071533 sec\n",
      "\n",
      "Epoch 157 Training Loss 0.193923\n",
      "Time taken for 1 epoch 1.714343547821045 sec\n",
      "\n",
      "Epoch 158 Training Loss 0.193652\n",
      "Time taken for 1 epoch 1.727721929550171 sec\n",
      "\n",
      "Epoch 159 Training Loss 0.193369\n",
      "Time taken for 1 epoch 1.7115478515625 sec\n",
      "\n",
      "Epoch 160 Training Loss 0.193098\n",
      "Time taken for 1 epoch 1.728173017501831 sec\n",
      "\n",
      "Epoch 161 Training Loss 0.192829\n",
      "Time taken for 1 epoch 1.71730375289917 sec\n",
      "\n",
      "Epoch 162 Training Loss 0.192555\n",
      "Time taken for 1 epoch 1.7115044593811035 sec\n",
      "\n",
      "Epoch 163 Training Loss 0.192361\n",
      "Time taken for 1 epoch 1.7581145763397217 sec\n",
      "\n",
      "Epoch 164 Training Loss 0.192321\n",
      "Time taken for 1 epoch 1.727292537689209 sec\n",
      "\n",
      "Epoch 165 Training Loss 0.192256\n",
      "Time taken for 1 epoch 1.711944341659546 sec\n",
      "\n",
      "Epoch 166 Training Loss 0.192162\n",
      "Time taken for 1 epoch 1.7259585857391357 sec\n",
      "\n",
      "Epoch 167 Training Loss 0.192030\n",
      "Time taken for 1 epoch 1.720714807510376 sec\n",
      "\n",
      "Epoch 168 Training Loss 0.191881\n",
      "Time taken for 1 epoch 1.7193872928619385 sec\n",
      "\n",
      "Epoch 169 Training Loss 0.191703\n",
      "Time taken for 1 epoch 1.7284400463104248 sec\n",
      "\n",
      "Epoch 170 Training Loss 0.191514\n",
      "Time taken for 1 epoch 1.731855869293213 sec\n",
      "\n",
      "Epoch 171 Training Loss 0.191317\n",
      "Time taken for 1 epoch 1.7325494289398193 sec\n",
      "\n",
      "Epoch 172 Training Loss 0.191109\n",
      "Time taken for 1 epoch 1.721541166305542 sec\n",
      "\n",
      "Epoch 173 Training Loss 0.190896\n",
      "Time taken for 1 epoch 1.7302680015563965 sec\n",
      "\n",
      "Epoch 174 Training Loss 0.190671\n",
      "Time taken for 1 epoch 1.7277238368988037 sec\n",
      "\n",
      "Epoch 175 Training Loss 0.190445\n",
      "Time taken for 1 epoch 1.7156710624694824 sec\n",
      "\n",
      "Epoch 176 Training Loss 0.190219\n",
      "Time taken for 1 epoch 1.7271645069122314 sec\n",
      "\n",
      "Epoch 177 Training Loss 0.190018\n",
      "Time taken for 1 epoch 1.7304229736328125 sec\n",
      "\n",
      "Epoch 178 Training Loss 0.189817\n",
      "Time taken for 1 epoch 1.7325475215911865 sec\n",
      "\n",
      "Epoch 179 Training Loss 0.189616\n",
      "Time taken for 1 epoch 1.723909616470337 sec\n",
      "\n",
      "Epoch 180 Training Loss 0.189406\n",
      "Time taken for 1 epoch 1.7215042114257812 sec\n",
      "\n",
      "Epoch 181 Training Loss 0.189193\n",
      "Time taken for 1 epoch 1.716547966003418 sec\n",
      "\n",
      "Epoch 182 Training Loss 0.188974\n",
      "Time taken for 1 epoch 1.7203378677368164 sec\n",
      "\n",
      "Epoch 183 Training Loss 0.188750\n",
      "Time taken for 1 epoch 1.7352275848388672 sec\n",
      "\n",
      "Epoch 184 Training Loss 0.188523\n",
      "Time taken for 1 epoch 1.761080026626587 sec\n",
      "\n",
      "Epoch 185 Training Loss 0.188305\n",
      "Time taken for 1 epoch 1.7213289737701416 sec\n",
      "\n",
      "Epoch 186 Training Loss 0.188096\n",
      "Time taken for 1 epoch 1.7267582416534424 sec\n",
      "\n",
      "Epoch 187 Training Loss 0.187887\n",
      "Time taken for 1 epoch 1.7186839580535889 sec\n",
      "\n",
      "Epoch 188 Training Loss 0.187672\n",
      "Time taken for 1 epoch 1.7248868942260742 sec\n",
      "\n",
      "Epoch 189 Training Loss 0.187463\n",
      "Time taken for 1 epoch 1.7303907871246338 sec\n",
      "\n",
      "Epoch 190 Training Loss 0.187257\n",
      "Time taken for 1 epoch 1.7383346557617188 sec\n",
      "\n",
      "Epoch 191 Training Loss 0.187071\n",
      "Time taken for 1 epoch 1.723585844039917 sec\n",
      "\n",
      "Epoch 192 Training Loss 0.186900\n",
      "Time taken for 1 epoch 1.7229840755462646 sec\n",
      "\n",
      "Epoch 193 Training Loss 0.186708\n",
      "Time taken for 1 epoch 1.7274971008300781 sec\n",
      "\n",
      "Epoch 194 Training Loss 0.186517\n",
      "Time taken for 1 epoch 1.7262296676635742 sec\n",
      "\n",
      "Epoch 195 Training Loss 0.186321\n",
      "Time taken for 1 epoch 1.7331628799438477 sec\n",
      "\n",
      "Epoch 196 Training Loss 0.186131\n",
      "Time taken for 1 epoch 1.7262732982635498 sec\n",
      "\n",
      "Epoch 197 Training Loss 0.185939\n",
      "Time taken for 1 epoch 1.7265534400939941 sec\n",
      "\n",
      "Epoch 198 Training Loss 0.185751\n",
      "Time taken for 1 epoch 1.7228949069976807 sec\n",
      "\n",
      "Epoch 199 Training Loss 0.185555\n",
      "Time taken for 1 epoch 1.733489990234375 sec\n",
      "\n",
      "Epoch 200 Training Loss 0.185369\n",
      "Time taken for 1 epoch 1.7384555339813232 sec\n",
      "\n",
      "Epoch 201 Training Loss 0.185181\n",
      "Time taken for 1 epoch 1.7468805313110352 sec\n",
      "\n",
      "Epoch 202 Training Loss 0.184988\n",
      "Time taken for 1 epoch 1.739015817642212 sec\n",
      "\n",
      "Epoch 203 Training Loss 0.184800\n",
      "Time taken for 1 epoch 1.7328102588653564 sec\n",
      "\n",
      "Epoch 204 Training Loss 0.184604\n",
      "Time taken for 1 epoch 1.7283437252044678 sec\n",
      "\n",
      "Epoch 205 Training Loss 0.184407\n",
      "Time taken for 1 epoch 1.7213270664215088 sec\n",
      "\n",
      "Epoch 206 Training Loss 0.184221\n",
      "Time taken for 1 epoch 1.7294962406158447 sec\n",
      "\n",
      "Epoch 207 Training Loss 0.184025\n",
      "Time taken for 1 epoch 1.7286460399627686 sec\n",
      "\n",
      "Epoch 208 Training Loss 0.183830\n",
      "Time taken for 1 epoch 1.7245795726776123 sec\n",
      "\n",
      "Epoch 209 Training Loss 0.183634\n",
      "Time taken for 1 epoch 1.7186589241027832 sec\n",
      "\n",
      "Epoch 210 Training Loss 0.183441\n",
      "Time taken for 1 epoch 1.7121806144714355 sec\n",
      "\n",
      "Epoch 211 Training Loss 0.183251\n",
      "Time taken for 1 epoch 1.7211425304412842 sec\n",
      "\n",
      "Epoch 212 Training Loss 0.183067\n",
      "Time taken for 1 epoch 1.7113392353057861 sec\n",
      "\n",
      "Epoch 213 Training Loss 0.182877\n",
      "Time taken for 1 epoch 1.7143316268920898 sec\n",
      "\n",
      "Epoch 214 Training Loss 0.182691\n",
      "Time taken for 1 epoch 1.7249431610107422 sec\n",
      "\n",
      "Epoch 215 Training Loss 0.182541\n",
      "Time taken for 1 epoch 1.7399446964263916 sec\n",
      "\n",
      "Epoch 216 Training Loss 0.182411\n",
      "Time taken for 1 epoch 1.716921329498291 sec\n",
      "\n",
      "Epoch 217 Training Loss 0.182286\n",
      "Time taken for 1 epoch 1.7217471599578857 sec\n",
      "\n",
      "Epoch 218 Training Loss 0.182162\n",
      "Time taken for 1 epoch 1.7265009880065918 sec\n",
      "\n",
      "Epoch 219 Training Loss 0.182047\n",
      "Time taken for 1 epoch 1.7181131839752197 sec\n",
      "\n",
      "Epoch 220 Training Loss 0.181952\n",
      "Time taken for 1 epoch 1.7227847576141357 sec\n",
      "\n",
      "Epoch 221 Training Loss 0.181899\n",
      "Time taken for 1 epoch 1.7141590118408203 sec\n",
      "\n",
      "Epoch 222 Training Loss 0.181823\n",
      "Time taken for 1 epoch 1.7046592235565186 sec\n",
      "\n",
      "Epoch 223 Training Loss 0.181746\n",
      "Time taken for 1 epoch 1.716271162033081 sec\n",
      "\n",
      "Epoch 224 Training Loss 0.181667\n",
      "Time taken for 1 epoch 1.7138679027557373 sec\n",
      "\n",
      "Epoch 225 Training Loss 0.181583\n",
      "Time taken for 1 epoch 1.7356326580047607 sec\n",
      "\n",
      "Epoch 226 Training Loss 0.181490\n",
      "Time taken for 1 epoch 1.7370357513427734 sec\n",
      "\n",
      "Epoch 227 Training Loss 0.181387\n",
      "Time taken for 1 epoch 1.73298978805542 sec\n",
      "\n",
      "Epoch 228 Training Loss 0.181260\n",
      "Time taken for 1 epoch 1.7130928039550781 sec\n",
      "\n",
      "Epoch 229 Training Loss 0.181121\n",
      "Time taken for 1 epoch 1.7140605449676514 sec\n",
      "\n",
      "Epoch 230 Training Loss 0.180976\n",
      "Time taken for 1 epoch 1.74583101272583 sec\n",
      "\n",
      "Epoch 231 Training Loss 0.180828\n",
      "Time taken for 1 epoch 1.7191243171691895 sec\n",
      "\n",
      "Epoch 232 Training Loss 0.180683\n",
      "Time taken for 1 epoch 1.7204580307006836 sec\n",
      "\n",
      "Epoch 233 Training Loss 0.180534\n",
      "Time taken for 1 epoch 1.7357358932495117 sec\n",
      "\n",
      "Epoch 234 Training Loss 0.180382\n",
      "Time taken for 1 epoch 1.7277371883392334 sec\n",
      "\n",
      "Epoch 235 Training Loss 0.180232\n",
      "Time taken for 1 epoch 1.730320692062378 sec\n",
      "\n",
      "Epoch 236 Training Loss 0.180092\n",
      "Time taken for 1 epoch 1.7240123748779297 sec\n",
      "\n",
      "Epoch 237 Training Loss 0.180013\n",
      "Time taken for 1 epoch 1.725928544998169 sec\n",
      "\n",
      "Epoch 238 Training Loss 0.179941\n",
      "Time taken for 1 epoch 1.7166941165924072 sec\n",
      "\n",
      "Epoch 239 Training Loss 0.179865\n",
      "Time taken for 1 epoch 1.724628210067749 sec\n",
      "\n",
      "Epoch 240 Training Loss 0.179788\n",
      "Time taken for 1 epoch 1.7183995246887207 sec\n",
      "\n",
      "Epoch 241 Training Loss 0.179718\n",
      "Time taken for 1 epoch 1.7203834056854248 sec\n",
      "\n",
      "Epoch 242 Training Loss 0.179638\n",
      "Time taken for 1 epoch 1.720604419708252 sec\n",
      "\n",
      "Epoch 243 Training Loss 0.179543\n",
      "Time taken for 1 epoch 1.7150084972381592 sec\n",
      "\n",
      "Epoch 244 Training Loss 0.179445\n",
      "Time taken for 1 epoch 1.7374958992004395 sec\n",
      "\n",
      "Epoch 245 Training Loss 0.179353\n",
      "Time taken for 1 epoch 1.713075876235962 sec\n",
      "\n",
      "Epoch 246 Training Loss 0.179245\n",
      "Time taken for 1 epoch 1.722491979598999 sec\n",
      "\n",
      "Epoch 247 Training Loss 0.179134\n",
      "Time taken for 1 epoch 1.7239508628845215 sec\n",
      "\n",
      "Epoch 248 Training Loss 0.179017\n",
      "Time taken for 1 epoch 1.724595069885254 sec\n",
      "\n",
      "Epoch 249 Training Loss 0.178897\n",
      "Time taken for 1 epoch 1.708526849746704 sec\n",
      "\n",
      "Epoch 250 Training Loss 0.178776\n",
      "Time taken for 1 epoch 1.7137107849121094 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# epochs\n",
    "EPOCHS = 250\n",
    "\n",
    "# define loss\n",
    "training_loss = tensorflow.keras.metrics.Mean(name='training_loss')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    # get the batch\n",
    "    for (batch, (img_tensor1_train, img_tensor2_train, target_train)) in enumerate(dataset_train):\n",
    "        # go to training step\n",
    "        t_loss = train_step(img_tensor1_train, img_tensor2_train, target_train)\n",
    "        # normalize loss over the data\n",
    "        training_loss(t_loss)\n",
    "    \n",
    "    print ('Epoch {} Training Loss {:.6f}'.format(epoch + 1, training_loss.result()))\n",
    "    \n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VvgixpsZJ7On",
    "outputId": "51bf1e4e-bdd2-4949-99c1-06becd8a43b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train BLEU score 0.442821\n",
      "Test BLEU score 0.442904\n"
     ]
    }
   ],
   "source": [
    "# calculate blue scores\n",
    "# train bleu score\n",
    "train_bleu = 0\n",
    "# get train df values\n",
    "data_train_vals = data_train.values\n",
    "for val in data_train_vals:\n",
    "    bleu = calc_blue(val[2], val[3], val[-1])\n",
    "    train_bleu += bleu\n",
    "train_bleu /= train_len\n",
    "\n",
    "print ('Train BLEU score {:.6f}'.format(train_bleu))\n",
    "\n",
    "# test bleu score\n",
    "test_bleu = 0\n",
    "# get test df values\n",
    "data_test_vals = data_test.values\n",
    "for val in data_test_vals:\n",
    "    bleu = calc_blue(val[2], val[3], val[-1])\n",
    "    test_bleu += bleu\n",
    "test_bleu /= test_len\n",
    "\n",
    "print ('Test BLEU score {:.6f}'.format(test_bleu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0xpBYcXyYp8"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8gifbJhdkZRc"
   },
   "outputs": [],
   "source": [
    "# this function will do greedy search\n",
    "def greedy_search(img1, img2, target):\n",
    "    # reset hidden states\n",
    "    hidden = decoder.reset_state(batch_size=1)\n",
    "    # reshape img vectors\n",
    "    img1 = tensorflow.keras.backend.reshape(img1, shape=(1, -1))\n",
    "    img2 = tensorflow.keras.backend.reshape(img2, shape=(1, -1))\n",
    "    # get image features\n",
    "    features1 = encoder1(img1)\n",
    "    features2 = encoder2(img2)\n",
    "    # decoder input = start\n",
    "    dec_input = tensorflow.expand_dims([impression_tokenizer.word_index['<start>']], 0)\n",
    "    result = []\n",
    "    result.append('<start>')\n",
    "    # loop for pad length\n",
    "    for i in range(pad_length_impression):\n",
    "        \n",
    "        # get predections\n",
    "        predictions, hidden = decoder(dec_input, features1, features2, hidden)\n",
    "        # get argmax of predicted id\n",
    "        predicted_id = predictions.numpy().argmax()\n",
    "        result.append(impression_tokenizer.index_word[predicted_id])\n",
    "        # if end is reached return\n",
    "        if impression_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result\n",
    "        # predicted output = next input\n",
    "        dec_input = tensorflow.expand_dims([predicted_id], 0)\n",
    "    # return\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VH9mChUWdm9",
    "outputId": "cb20feae-89a0-402e-fe1d-e06286c04752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________NEW__DATA__POINT___________________________________________________\n",
      "Actual Impression  <start> no acute cardiopulmonary disease <end>\n",
      "Generated Impression  ['<start>', 'no', 'acute', 'disease', '<end>']\n",
      "___________________________________________________NEW__DATA__POINT___________________________________________________\n",
      "Actual Impression  <start> no acute cardiopulmonary abnormality <end>\n",
      "Generated Impression  ['<start>', 'no', 'acute', 'cardiopulmonary', 'disease', '<end>']\n",
      "___________________________________________________NEW__DATA__POINT___________________________________________________\n",
      "Actual Impression  <start> no acute cardiopulmonary disease <end>\n",
      "Generated Impression  ['<start>', 'no', 'acute', 'disease', 'negative', 'for', 'hemoptysis', 'to', 'previous', 'acute', 'disease', 'negative', 'for', 'hemoptysis', 'to', 'previous', 'acute', 'disease', 'negative', 'for', 'hemoptysis', 'to', 'previous', 'acute', 'disease', 'negative', 'for', 'hemoptysis', 'to', 'previous', 'acute', 'disease', 'negative', 'for', 'hemoptysis', 'to', 'previous', 'acute', 'disease', 'negative', 'for']\n",
      "___________________________________________________NEW__DATA__POINT___________________________________________________\n",
      "Actual Impression  <start> no acute changes from prior imaging <end>\n",
      "Generated Impression  ['<start>', 'no', 'acute', 'cardiopulmonary', 'disease', '<end>']\n",
      "___________________________________________________NEW__DATA__POINT___________________________________________________\n",
      "Actual Impression  <start> right upper lobe mass, suspicious for neoplasm ct of chest abdomen and head would be helpful for further evaluation <end>\n",
      "Generated Impression  ['<start>', 'no', 'acute', 'cardiopulmonary', 'disease', '<end>']\n"
     ]
    }
   ],
   "source": [
    "# get 5 random samples\n",
    "data_eval = data.sample(5)\n",
    "data_eval_vals = data_eval.values\n",
    "\n",
    "# print greedy search outputs\n",
    "for val in data_eval_vals:\n",
    "    print('___________________________________________________NEW__DATA__POINT___________________________________________________')\n",
    "    result = greedy_search(val[3], val[4], val[5])\n",
    "    print('Actual Impression ', val[5])\n",
    "    print('Generated Impression ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "m-4qNABeWexa"
   },
   "outputs": [],
   "source": [
    "# this function will do beam search\n",
    "def beam_search(img1, img2, target, beam_width = 5):\n",
    "\n",
    "    # reset hidden states\n",
    "    hidden = decoder.reset_state(batch_size=1)\n",
    "    # reshape img vectors\n",
    "    img1 = tensorflow.keras.backend.reshape(img1, shape=(1, -1))\n",
    "    img2 = tensorflow.keras.backend.reshape(img2, shape=(1, -1))\n",
    "    # get image features\n",
    "    features1 = encoder1(img1)\n",
    "    features2 = encoder2(img2)\n",
    "    # decoder input = start\n",
    "    start = [impression_tokenizer.word_index['<start>']]\n",
    "    start_word = [[start, 0.0]]\n",
    "    \n",
    "    while len(start_word[0][0]) < pad_length_impression:\n",
    "        temp = []\n",
    "        for s in start_word:\n",
    "            \n",
    "            dec_input = pad_sequences([[s[0][-1]]])\n",
    "            # get the predections \n",
    "            preds, hidden = decoder(dec_input, features1, features2, hidden)\n",
    "            \n",
    "            # Getting the top <beam_width>(n) predictions\n",
    "            top_words = np.argsort(preds).flatten()\n",
    "            word_preds = top_words[-beam_width:]\n",
    "            \n",
    "            # creating a new list so as to put them via the model again\n",
    "            for w in word_preds:\n",
    "                next_cap, prob = s[0][:], s[1]\n",
    "                next_cap.append(w)\n",
    "                prob += preds[0][w]\n",
    "                temp.append([next_cap, prob])\n",
    "                    \n",
    "        start_word = temp\n",
    "        # Sorting according to the probabilities\n",
    "        start_word = sorted(start_word, reverse=False, key=lambda l: l[1])\n",
    "        # Getting the top words\n",
    "        start_word = start_word[-beam_width:]\n",
    "    \n",
    "    # update start word\n",
    "    start_word = start_word[-1][0]\n",
    "    # intermediate caption\n",
    "    intermediate_caption = [impression_tokenizer.index_word[i] for i in start_word]\n",
    "    # generate final captions\n",
    "    final_caption = []\n",
    "    for i in intermediate_caption:\n",
    "        if i != '<end>':\n",
    "            final_caption.append(i)\n",
    "        else:\n",
    "            break\n",
    "    # return final captions\n",
    "    final_caption = final_caption[1:]\n",
    "    final_caption.insert(0, '<start>')\n",
    "    if len(final_caption) <= 39:\n",
    "        final_caption.append('<end>')\n",
    "    return final_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEFb4fISWeuY",
    "outputId": "4d99387a-9dba-4a2f-a3da-75ec49d13c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________NEW__DATA__POINT___________________________________________________\n",
      "Actual Impression  <start> no acute disease <end>\n",
      "Generated Impression  ['<start>', 'no', 'focal', 'areas', 'of', 'cystic', 'fibrosis', '<end>']\n",
      "___________________________________________________NEW__DATA__POINT___________________________________________________\n",
      "Actual Impression  <start> no acute findings <end>\n",
      "Generated Impression  ['<start>', 'normal', 'clear', 'lungs', 'otherwise', 'clear', 'lungs', 'otherwise', 'clear', 'lungs', 'otherwise', 'clear', 'lungs', 'otherwise', 'clear', 'lungs', 'otherwise', 'clear', 'lungs', 'otherwise', 'clear', 'lungs', 'otherwise', 'clear', 'lungs', 'otherwise', 'clear', 'lungs', 'otherwise', 'clear', 'lungs', 'otherwise', 'clear', 'lungs', 'otherwise', 'clear', 'lungs', 'otherwise', 'clear', 'lungs']\n",
      "___________________________________________________NEW__DATA__POINT___________________________________________________\n",
      "Actual Impression  <start> left retrocardiac airspace disease could reflect atelectasis and possible scarring small left pleural effusion <end>\n",
      "Generated Impression  ['<start>', 'no', 'radiographic', 'radiographic', 'cardiopulmonary', 'abnormalities', 'are', 'seen', '<end>']\n",
      "___________________________________________________NEW__DATA__POINT___________________________________________________\n",
      "Actual Impression  <start> clear lungs <end>\n",
      "Generated Impression  ['<start>', 'no', 'acute', 'disease', 'otherwise', 'clear', 'lungs', 'without', 'acute', 'disease', '<end>']\n",
      "___________________________________________________NEW__DATA__POINT___________________________________________________\n",
      "Actual Impression  <start> negative for acute abnormality <end>\n",
      "Generated Impression  ['<start>', 'no', 'focal', 'areas', 'of', 'early', 'pneumonia', '<end>']\n"
     ]
    }
   ],
   "source": [
    "# get 5 random samples\n",
    "data_eval = data.sample(5)\n",
    "data_eval_vals = data_eval.values\n",
    "\n",
    "# print beam search outputs\n",
    "for val in data_eval_vals:\n",
    "    print('___________________________________________________NEW__DATA__POINT___________________________________________________')\n",
    "    result = beam_search(val[3], val[4], val[5], 5)\n",
    "    print('Actual Impression ', val[5])\n",
    "    print('Generated Impression ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "bMn2QVAtBMha"
   },
   "outputs": [],
   "source": [
    "encoder1.save_weights(drive_path + '/encoder1_weights', save_format='tf')\n",
    "encoder2.save_weights(drive_path + '/encoder2_weights', save_format='tf')\n",
    "decoder.save_weights(drive_path + '/decoder_weights', save_format='tf')\n",
    "\n",
    "encoder1.save_weights(drive_path + '/encoder1.h5')\n",
    "encoder2.save_weights(drive_path + '/encoder2.h5')\n",
    "decoder.save_weights(drive_path + '/decoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTOwehZIJQUt"
   },
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I63HZgeuJywd"
   },
   "source": [
    "- In this Notebook we used the Bahdanau Attention and Teacher Forcing Technique to train the Models\n",
    "- We used the GRU's as \n",
    "- We used Greedy Search and Beam Search to generate the Impression\n",
    "- We also used Masked Loss in this notebook\n",
    "- The Bleu Score that we got from our model is 0.44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcweE2DgaFCE"
   },
   "source": [
    "## References\n",
    "\n",
    "- https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
    "- https://www.tensorflow.org/tutorials/text/nmt_with_attention#write_the_encoder_and_decoder_model\n",
    "- https://stackoverflow.com/questions/50786987/multiclass-classification-to-balance-in-python-over-sampling\n",
    "- https://radimrehurek.com/gensim/models/word2vec.html\n",
    "- https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "- https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "- https://github.com/nagapavan525/radiology-report-generation/blob/master/radiology_report_generation_final/Automated_Radiology_Report_Generation_attention%20(1).ipynb\n",
    "- https://github.com/nagapavan525/radiology-report-generation/blob/master/NewIntegrationWithIndication/1_Capstone-Radiology-PreProcessing.ipynb\n",
    "- https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "- https://stackoverflow.com/questions/2612548/extracting-an-attribute-value-with-beautifulsoup\n",
    "- https://stackoverflow.com/questions/24962673/beautiful-soup-getting-tag-id\n",
    "- https://stackoverflow.com/a/47091490/4084039\n",
    "- https://www.appservgrid.com/psam/Python_Samplifier--python1compute--Python_Program_to_Find_the_Size_(Resolution)_of_a_Image.html\n",
    "- https://www.geeksforgeeks.org/working-images-python/\n",
    "- https://gist.github.com/sebleier/554280\n",
    "- https://stackoverflow.com/questions/27488446/how-do-i-get-word-frequency-in-a-corpus-using-scikit-learn-countvectorizer\n",
    "- https://www.geeksforgeeks.org/python-remove-all-digits-from-a-list-of-strings/\n",
    "- https://stackoverflow.com/questions/12851791/removing-numbers-from-string\n",
    "- https://github.com/nagapavan525/radiology-report-generation/blob/master/radiology_report_generation_final/AutomatedRadiologyReportGenerationWithSentenceEmbeddings.ipynb\n",
    "- https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "BcweE2DgaFCE"
   ],
   "name": "Tensorflow_Gru.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
